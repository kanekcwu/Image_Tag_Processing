{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color='#333333'>Hack the Rack 2018</font></center>\n",
    "## <center><font color='#808080'>Challenge 2: Image Tag Processing</font></center> \n",
    "### <center><font color='#3b5998'>Created by cyda - Yeung Wong & Carrie Lo</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "![logo](https://4.bp.blogspot.com/-LAXjdvVCYCU/WxeQFKQ-1wI/AAAAAAAAACs/o8IJ1eLLAEwQYv2Az7EqQi9jODTqRx7wACK4BGAYYCw/s1000/tight%2Bbanner_with_description.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "Please acknowledge <b>team cyda - Yeung Wong and Carrie Lo</b> when using the code\n",
    "\n",
    "<b><font color='#3b5998'>If you find this script is helpful, please feel free to endorse us through Linkedin!</font></b>\n",
    "\n",
    "<b>Linkedin:</b>\n",
    "\n",
    "Yeung Wong - https://www.linkedin.com/in/yeungwong/\n",
    "\n",
    "Carrie Lo - https://www.linkedin.com/in/carrielsc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "\n",
    "#### Challenge Description\n",
    "\n",
    "<u>Humanizing image search for inspiration</u>\n",
    "\n",
    "This project is intentionally made to process the text data of the tagging of over 25,000 images provided by Li and Fung so as to make a search engine of their products more easily and effectively. Therefore, in order to facilitate their daily works, we drill down our challenge into two main focuses\n",
    "\n",
    "- Part 1: Clean the input dataset from two different APIs and create a Image_Tag master dataset\n",
    "- Part 2: Leverage pretrained neural network to enhance the customer search experience\n",
    "\n",
    "Example of the Image_Tag master dataset\n",
    "    | pic_id | tags     |\n",
    "    ---------------------\n",
    "    | pic001 | \"dress\"  |\n",
    "    | pic001 | \"pink\"   |\n",
    "    | pic001 | \"summer\" |\n",
    "    | pic002 | \"hat\"    |\n",
    "    | ...    |  ...     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "\n",
    "#### Reminder\n",
    "\n",
    "Please make sure you check the below checkpoints before running the script.\n",
    "\n",
    "1. This script is Part 2 of the challenge. For details in Part 1 which is worked in the R environment, you may check thought our github - cydalytics.\n",
    "2. Make sure the file path is correct and the files are following the hirarchy. (Please refer <u>1.2 define the path</u> for detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "\n",
    "#### Data we use\n",
    "\n",
    "Input:\n",
    "- Pretrained data - GoogleNews-vectors-negative300-SLIM.bin\n",
    "- Processed data - json_atr_tag_dataset.csv\n",
    "- Raw data - images file (Optional: just for interactive data exploration)\n",
    "\n",
    "Output:\n",
    "- Processed data - synonyms_list (for pbi).csv (Optional: for further data visualization analysis)\n",
    "> If you are interested in knowing how these synonyms can be further analysed and presented in the data visualization tools\n",
    "  such as PowerBI, please visit https://cydalytics.blogspot.com/\n",
    "\n",
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 import libraries and set global parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yyyeu\\Anaconda2\\envs\\datasci_py3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Data Visualization\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Text Mining\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Neural Networking Model\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Parameter - To stop potential randomness\n",
    "seed = 494 # Li & Fung Limited Stock Index\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 define the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('')\n",
    "pretrained_dir = os.path.join(root_dir, 'Data\\Pretrained & External Data')\n",
    "processed_dir = os.path.join(root_dir, 'Data\\Result & Processed Data')\n",
    "# image_dir is optional and we will not include images in order to reduce the running time\n",
    "# image_dir = os.path.join(root_dir, 'Data\\Raw Data\\Images')\n",
    "image_dir = os.path.join('G:/My Drive/WHY/Data Science/Projects/20180622 Hack The Rack/Dataset/Challenge 2 - Image Tagging/Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 import processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>pkeyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>941234bleach1_1_20160414065445545.jpg</td>\n",
       "      <td>solid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>941234bleach1_1_20160414065445545.jpg</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>941234bleach1_1_20160414065445545.jpg</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>941234bleach1_1_20160414065445545.jpg</td>\n",
       "      <td>long sleeve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941234bleach1_1_20160414065445545.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>941234bleach1_1_20160414065445545.jpg</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>140172472_3_20161214075635169.jpg</td>\n",
       "      <td>solid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>140172472_3_20161214075635169.jpg</td>\n",
       "      <td>gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>140172472_3_20161214075635169.jpg</td>\n",
       "      <td>sleeveless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>538037checkpattern_1_20160525091219305.jpg</td>\n",
       "      <td>geometric print</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pid         pkeyword\n",
       "0       941234bleach1_1_20160414065445545.jpg            solid\n",
       "1       941234bleach1_1_20160414065445545.jpg             blue\n",
       "2       941234bleach1_1_20160414065445545.jpg           female\n",
       "3       941234bleach1_1_20160414065445545.jpg      long sleeve\n",
       "4       941234bleach1_1_20160414065445545.jpg               no\n",
       "5       941234bleach1_1_20160414065445545.jpg            adult\n",
       "6           140172472_3_20161214075635169.jpg            solid\n",
       "7           140172472_3_20161214075635169.jpg             gray\n",
       "8           140172472_3_20161214075635169.jpg       sleeveless\n",
       "9  538037checkpattern_1_20160525091219305.jpg  geometric print"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_keyword_df = pd.read_csv(os.path.join(processed_dir, 'json_atr_tag_dataset.csv'))\n",
    "photo_keyword_df.columns = ['pid', 'pkeyword']\n",
    "photo_keyword_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 import images (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly not suggested to import the images as it takes many time\n",
    "\n",
    "In the reality, the app should be directly connected with the cloud service which mapped the images with the image ID\n",
    "\n",
    "But in order to show that it works, we will use 1000 pictures as demostration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for demostration\n",
    "image_id = list(set(photo_keyword_df['pid']))[0:1000]\n",
    "len(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage_id = np.asarray(os.listdir(image_dir))\\nimage_id\\n\\nfor j in reversed(range(len(image_id))):\\n    if image_id[j][0] == \".\":\\n        hidden_index = image_id.tolist().index(image_id[j])\\n        image_id = np.delete(image_id, hidden_index)\\n\\nif \\'desktop.ini\\' in image_id:\\n    desktop_ini_index = image_id.tolist().index(\\'desktop.ini\\')\\n    image_id = np.delete(image_id, desktop_ini_index)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for full set of images\n",
    "'''\n",
    "image_id = np.asarray(os.listdir(image_dir))\n",
    "image_id\n",
    "\n",
    "for j in reversed(range(len(image_id))):\n",
    "    if image_id[j][0] == \".\":\n",
    "        hidden_index = image_id.tolist().index(image_id[j])\n",
    "        image_id = np.delete(image_id, hidden_index)\n",
    "\n",
    "if 'desktop.ini' in image_id:\n",
    "    desktop_ini_index = image_id.tolist().index('desktop.ini')\n",
    "    image_id = np.delete(image_id, desktop_ini_index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_pic = []\n",
    "\n",
    "for k in range(len(image_id)):\n",
    "    img_id_temp =image_id[k]\n",
    "for image_id_prototype in image_id:\n",
    "    img_id_temp =image_id_prototype\n",
    "    filepath = os.path.join(image_dir, img_id_temp)\n",
    "    image_pic.append(imageio.imread(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>image_pointer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m_1249592_1_20170919181229000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140170842_1_20161216081959358.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p_1440664_1_20170925095647000.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>542792sailorwhitestp_1_20161209022043798.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h_831855_1_20170827164527000.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pid  image_pointer\n",
       "0             m_1249592_1_20170919181229000.jpg              0\n",
       "1             140170842_1_20161216081959358.jpg              1\n",
       "2             p_1440664_1_20170925095647000.jpg              2\n",
       "3  542792sailorwhitestp_1_20161209022043798.jpg              3\n",
       "4              h_831855_1_20170827164527000.jpg              4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_key_pointer_df = pd.DataFrame(image_id)\n",
    "image_key_pointer_df.columns = ['pid']\n",
    "\n",
    "image_key_pointer_df = image_key_pointer_df.reset_index()\n",
    "del image_key_pointer_df['index']\n",
    "\n",
    "image_key_pointer_df['image_pointer'] = range(len(image_pic))\n",
    "\n",
    "image_key_pointer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 create the master_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmaster_dataset = photo_keyword_df\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the one who runs the image part\n",
    "master_dataset = photo_keyword_df.merge(image_key_pointer_df, on='pid')\n",
    "\n",
    "# For the one who runs without the image part\n",
    "'''\n",
    "master_dataset = photo_keyword_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Image Exploration (Optional) (for those who imports the images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 explore the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da6b68bc06b46f5941c6f49cadd685d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=499, description='i', max=999), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def browse_images(image_id):\n",
    "    n = len(image_id)\n",
    "    def view_image(i):\n",
    "        plt.imshow(image_pic[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.xlabel(image_id[i], fontsize = 12)\n",
    "        plt.show()\n",
    "    interact(view_image, i=(0,n-1))\n",
    "    \n",
    "browse_images(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 explore the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e296c435994ee59bf2caef9d725509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=499, description='i', max=999), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def browse_master_dataset(image_id):\n",
    "    n = len(image_id)\n",
    "    def view_master_dataset(i):\n",
    "        if len(master_dataset[(master_dataset.pid == image_id[i])]) == 0:\n",
    "            print ('No Related Keywords')\n",
    "        if len(master_dataset[(master_dataset.pid == image_id[i])]) != 0:\n",
    "            print(master_dataset[(master_dataset.pid == image_id[i])][['pkeyword']].to_string(index=False, header = False))\n",
    "    interact(view_master_dataset, i=(0,n-1))\n",
    "    \n",
    "browse_master_dataset(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 explore the images and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def browse_images2(image_id):\n",
    "    n = len(image_id)\n",
    "    def view_image2(i):\n",
    "        plt.imshow(image_pic[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.xlabel(image_id[i], fontsize = 12)\n",
    "        plt.show()\n",
    "        \n",
    "        if len(master_dataset[(master_dataset.pid == image_id[i])]) == 0:\n",
    "            print ('No Related Keywords')\n",
    "        if len(master_dataset[(master_dataset.pid == image_id[i])]) != 0:\n",
    "            print(master_dataset[(master_dataset.pid == image_id[i])][['pkeyword']].to_string(index=False, header = False)) \n",
    "    interact(view_image2, i=(0,n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549c19cc9a92487a846b0f4398bce833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=499, description='i', max=999), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "browse_images2(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Search Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 text preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(_text, method='lemm'):\n",
    "    \n",
    "    # Tokenize and keep only english chars\n",
    "    words = nltk.wordpunct_tokenize(re.sub('[^a-zA-Z]', ' ', _text))\n",
    "    # Change to lower case\n",
    "    words = [x.lower() for x in words]\n",
    "    \n",
    "    # keep words length > 1\n",
    "    words = [x for x in words if len(x)>1]\n",
    "    \n",
    "    # Lemmatizing or stemming\n",
    "    if method == 'lemm':\n",
    "        wnl = WordNetLemmatizer()\n",
    "        words = [wnl.lemmatize(w) for w in words]\n",
    "    elif method == 'stem':\n",
    "        port = PorterStemmer()\n",
    "        words = [port.stem(w) for w in words]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyword_search(keyword_input):\n",
    "    keyword_input = text_preprocessing(keyword_input, 'lemm')\n",
    "    if len(master_dataset[(master_dataset.pkeyword == keyword_input)]) == 0:\n",
    "        print ('No Related Keywords')\n",
    "        \n",
    "    if len(master_dataset[(master_dataset.pkeyword == keyword_input)]) != 0:\n",
    "        temp_dataset = master_dataset[(master_dataset.pkeyword == keyword_input)][['pid','image_pointer']]\n",
    "        n = len(temp_dataset)\n",
    "        def display_result(i):\n",
    "            plt.imshow(image_pic[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "            plt.xlabel(image_id[i], fontsize = 12)\n",
    "            plt.show()        \n",
    "        interact(display_result, i=np.asarray(temp_dataset['image_pointer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46665784bbe24e3ab4404a3844226962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='i', options=(31, 852, 348, 835, 280, 695, 3, 586, 8, 152, 247, 524…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword_search('female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 combined keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_keyword_search(keyword_input1, keyword_input2):\n",
    "    keyword_input1 = text_preprocessing(keyword_input1, 'lemm')\n",
    "    keyword_input2 = text_preprocessing(keyword_input2, 'lemm')\n",
    "    \n",
    "    if (len(master_dataset[(master_dataset.pkeyword == keyword_input1)]) == 0)or(len(master_dataset[(master_dataset.pkeyword == keyword_input2)]) == 0):\n",
    "        print ('No Related Keywords')\n",
    "        \n",
    "    if (len(master_dataset[(master_dataset.pkeyword == keyword_input1)]) != 0)and(len(master_dataset[(master_dataset.pkeyword == keyword_input2)]) != 0):\n",
    "        temp_dataset = master_dataset[(master_dataset.pkeyword == keyword_input1)]\n",
    "        temp_pid = list(temp_dataset['pid'])\n",
    "        temp_dataset2 = master_dataset[master_dataset.pid.isin(temp_pid)]\n",
    "        temp_dataset3 = temp_dataset2[(temp_dataset2.pkeyword == keyword_input2)][['pid','image_pointer']]\n",
    "        n = len(temp_dataset3)\n",
    "        def display_result(i):\n",
    "            plt.imshow(image_pic[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "            plt.xlabel(image_id[i], fontsize = 12)\n",
    "            plt.show()        \n",
    "        interact(display_result, i=np.asarray(temp_dataset['image_pointer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06aea84fe05149a2894e25a3839bf725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='i', options=(398, 419, 397, 935, 321, 229, 622, 976, 279, 163, 214…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combine_keyword_search('male', 'round')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 relevant keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relevant_search_keyword(keyword_input):\n",
    "    keyword_input1 = text_preprocessing(keyword_input, 'lemm')\n",
    "    \n",
    "    if len(master_dataset[(master_dataset.pkeyword == keyword_input)]) == 0:\n",
    "        print ('No Related Keywords')\n",
    "        \n",
    "    if len(master_dataset[(master_dataset.pkeyword == keyword_input)]) != 0:\n",
    "        temp_dataset = master_dataset[(master_dataset.pkeyword == keyword_input)]\n",
    "        temp_pid = list(temp_dataset['pid'])\n",
    "        temp_dataset2 = master_dataset[master_dataset.pid.isin(temp_pid)]\n",
    "    \n",
    "    a = temp_dataset2\n",
    "\n",
    "    my_tab = pd.crosstab(index=temp_dataset2['pkeyword'], columns=\"count\")\n",
    "    my_tab = my_tab.sort_values('count', ascending=False)\n",
    "    max = my_tab['count'][0]\n",
    "    my_tab['count2'] = my_tab['count'] / max\n",
    "    \n",
    "    my_tab = my_tab[my_tab.count2 < 0.8]\n",
    "    \n",
    "    my_tab = my_tab[1:10]\n",
    "    \n",
    "    print(list(my_tab.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'solid', 'adult', 'black', 'long sleeve', 'short half', 'sleeveless', 'floral print', 'casual']\n"
     ]
    }
   ],
   "source": [
    "relevant_search_keyword('v neck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Synonyms Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is optional since it is not related to the challenge we are facing\n",
    "\n",
    "But it is useful for doing further analysis on showing how data can be leveraged and presented in the data visualization tool\n",
    "\n",
    "If you are interested in this field, feel free to visit https://cydalytics.blogspot.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 import pretrained neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_word_embedding = os.path.join(pretrained_dir, 'GoogleNews-vectors-negative300-SLIM.bin')\n",
    "model = KeyedVectors.load_word2vec_format(pretrained_word_embedding, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 synonyms analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yyyeu\\Anaconda2\\envs\\datasci_py3\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hoody', 0.7738105058670044),\n",
       " ('sweatshirt', 0.7398683428764343),\n",
       " ('hoodies', 0.7226213216781616),\n",
       " ('beanie', 0.6617897748947144),\n",
       " ('Hoodie', 0.6560907959938049),\n",
       " ('jacket', 0.6535500288009644),\n",
       " ('balaclava', 0.6209901571273804),\n",
       " ('bandana', 0.612551748752594),\n",
       " ('bandanna', 0.5987221002578735),\n",
       " ('shirt', 0.5979430675506592)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['hoodie'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yyyeu\\Anaconda2\\envs\\datasci_py3\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Tshirt', 0.6293981075286865),\n",
       " ('shirt', 0.5718910694122314),\n",
       " ('shirts', 0.5639886856079102),\n",
       " ('onesie', 0.5497466325759888),\n",
       " ('snuggie', 0.5451359748840332),\n",
       " ('hoodie', 0.543143630027771),\n",
       " ('gbr', 0.5220522880554199),\n",
       " ('woot', 0.515326738357544),\n",
       " ('sweatshirt', 0.5147799849510193),\n",
       " ('underoos', 0.5078185796737671)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['tshirt'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yyyeu\\Anaconda2\\envs\\datasci_py3\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('handbags', 0.7093594670295715),\n",
       " ('Handbag', 0.6531553268432617),\n",
       " ('satchel', 0.6487715244293213),\n",
       " ('wristlet', 0.6127949357032776),\n",
       " ('wallet', 0.5805193781852722),\n",
       " ('purse', 0.5770999193191528),\n",
       " ('holdall', 0.5732836723327637),\n",
       " ('briefcase', 0.5614685416221619),\n",
       " ('bag', 0.5601797103881836),\n",
       " ('necklace', 0.559670627117157)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['handbag'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shoelace'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"Dress Sunglasses Hat shoelace\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"Microsoft Waterbottle Water Agua\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 for further analysis on data visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlabels = ['synonyms', 'percentage']\\nresult = pd.DataFrame()\\n\\nfor i in photo_keyword_df['pkeyword']:\\n    try:\\n        temp = model.wv.most_similar([i],topn=10)\\n        temp_df = pd.DataFrame.from_records(temp, columns=labels)\\n        temp_df['Keyword'] = i\\n        result = result.append(temp_df, ignore_index=True)\\n    except:\\n        pass\\n\\nresult.head()\\n\\nresult.to_csv(os.path.join(processed_dir, 'synonyms_list (for pbi).csv'))\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "labels = ['synonyms', 'percentage']\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in photo_keyword_df['pkeyword']:\n",
    "    try:\n",
    "        temp = model.wv.most_similar([i],topn=10)\n",
    "        temp_df = pd.DataFrame.from_records(temp, columns=labels)\n",
    "        temp_df['Keyword'] = i\n",
    "        result = result.append(temp_df, ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "result.head()\n",
    "\n",
    "result.to_csv(os.path.join(processed_dir, 'synonyms_list (for pbi).csv'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "# <center><font color='#FF0000'>~ This</font> <font color='#FF7F00'>is</font> <font color='#FFFF00'>the</font> <font color='#00FF00'>end</font> <font color='#00FFFF'>of</font> <font color='#0000FF'>the</font> <font color='#8B00FF'>script ~</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "<b><font color='#3b5998'>If you appreciate our hard work, please endorse us through linkedin!</font></b>\n",
    "\n",
    "<b>Linkedin:</b>\n",
    "\n",
    "Yeung Wong - https://www.linkedin.com/in/yeungwong/\n",
    "\n",
    "Carrie Lo - https://www.linkedin.com/in/carrielsc/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datasci_py3]",
   "language": "python",
   "name": "conda-env-datasci_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
